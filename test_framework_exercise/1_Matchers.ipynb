{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose a software engineer becomes responsible for writing a function that finds pairs of strings that contain twos. \n",
    "\n",
    "It takes two lists of strings and returns integerizaitons of any elements that appear in both lists containing the digit 2.\n",
    "\n",
    "Here's a pretty terrible implementation of `find_twos`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_twos(first_list, second_list):\n",
    "    return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What could such an awful implementation of `find_twos` do for us?\n",
    "\n",
    "Well, not find twos, obviously. But we _could_ use it as an example case if we were to attempt to build a test framework of our own."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maybe our test framework starts out looking like this: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(function, examples):\n",
    "    passed = 0\n",
    "    run = 0\n",
    "\n",
    "    for example in examples:\n",
    "        run += 1\n",
    "        expected = example[-1]\n",
    "        actual = function(*example[:-1])\n",
    "\n",
    "        if expected == actual:\n",
    "            passed += 1\n",
    "        else:\n",
    "            print(f\"Whoops. For example {example}, the function returned {actual}.\")\n",
    "\n",
    "    print(f\"\\n{passed} out of {run} examples worked as expected.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The framework, so far, is just a function. It accepts a function and some examples as arguments, and it prints some stuff at the end.\n",
    "\n",
    "I wouldn't call that function intuitive to read. How might we demonstrate, _as quickly as posisble_, how someone might use our test framework?\n",
    "\n",
    "Would a README help us?\n",
    "\n",
    "What would be the advantages of a README? \n",
    "\n",
    "What might be its drawbacks?\n",
    "\n",
    "What if we try a usage example like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "FindTwosExample = namedtuple('FindTwosExample', ['list1', 'list2', 'expected_result'])\n",
    "\n",
    "find_twos_examples = [\n",
    "    FindTwosExample(list1=\"\", list2=\"\", expected_result=[]),\n",
    "    (\"1\", \"1, 3\", []),\n",
    "    (\"2\", \"\", []),\n",
    "    (\"2\", \"1, 3\", []),\n",
    "    (\"2\", \"2\", [2]),\n",
    "    (\"2\", \"12\", []),\n",
    "    (\"12\", \"2, 12\", [12]),\n",
    "    (\"1, 3, 5, 12, 7, 200\", \"2, 6, 9, 200, 5\", [200]),\n",
    "    (\"1, 2, 20, 22, 44, 99\", \"3, 5, 22, 100, 44, 2\", [2, 22]),\n",
    "    (\"1,2, 20,22, 44, 99\", \"3,5, 22, 100, 44, 2\", [2, 22]),\n",
    "    (\"1,2, 20,22, 22,44, 20, 99\", \"3,5, 22, 100, 44, 2\", [2, 22]),\n",
    "    (\"1, 2, 20, 22\", \"3, 2, 20, 22\", [2, 20, 22]),\n",
    "]\n",
    "\n",
    "# will run the find_twos function on all the examples in sequence\n",
    "test(function=find_twos, examples=find_twos_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does that illustrate how our test framework works?\n",
    "\n",
    "What _benefits_ does this demonstration have over a README? What drawbacks might it have? \n",
    "\n",
    "Would you add comments to code like this? Why or why not?\n",
    "\n",
    "If you were committing this method, what sort of commit message might you place on it?\n",
    "\n",
    "A senior-or-higher software engineer might consider themselves beyond these questions, but they form the bedrock of our approach to documentation as a team. We choose whether, and how, to make our past decisions discoverable and replicable. At scale, those choices impact the degree to which team members can self-serve the answers to their questions about their code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suppose we want to add a new component to our test framework: matchers.\n",
    "\n",
    "Let's see if we can get this to work:\n",
    "\n",
    "```\n",
    ">>> assert_that(find_twos(\"\", \"\")).equals([])\n",
    ">>> True\n",
    "\n",
    ">>> assert_that(find_twos(\"\", \"\")).equals([\"wrong answer\"])\n",
    ">>> FailedAssertion: Expected ['wrong answer'] but got []\n",
    "```\n",
    "\n",
    "Here's some code to get you started:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FailedAssertion(Exception):\n",
    "    pass\n",
    "\n",
    "class Assertion:\n",
    "    def __init__(self, expression):\n",
    "        self.expression = expression\n",
    "\n",
    "    def equals(self, expected_result):\n",
    "        '''\n",
    "            Should return true if the expression matches the expected result.\n",
    "            Otherwise should raise a FailedAssertion.\n",
    "        '''\n",
    "        \n",
    "def assert_that(expression):\n",
    "    return Assertion(expression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert_that(find_twos(\"\", \"\")).equals([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert_that(find_twos(\"\", \"\")).equals([\"wrong answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test frameworks often have a wide variety of matchers that programmers can use to write expressions describing all the things we want to check in our tests. We will write more matchers a little later, but `.equals()` is a great one to start with.\n",
    "\n",
    "We can use our `.equals()` matcher to write tests for `find_twos` like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def test_empty_inputs():\n",
    "        assert_that(find_twos(\"\", \"\")).equals([])\n",
    "        assert_that(find_twos(\"2\", \"\")).equals([])\n",
    "        assert_that(find_twos(\"2\", \"\")).equals([])\n",
    "\n",
    "    def test_non_matching_sets():\n",
    "        assert_that(find_twos(\"1\", \"1, 3\")).equals([])\n",
    "\n",
    "    def test_non_matching_twos():\n",
    "        assert_that(find_twos(\"2\", \"1, 3\")).equals([])\n",
    "        \n",
    "    def test_matches():\n",
    "        assert_that(find_twos(\"12\", \"2, 12\")).equals([12])\n",
    "        assert_that(find_twos(\"1, 2, 20, 22, 44, 99\", \"3, 5, 22, 100, 44, 2\")).equals([2, 22])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_empty_inputs()\n",
    "test_non_matching_sets()\n",
    "test_non_matching_twos()\n",
    "test_matches()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does your _equals_ matcher work now?\n",
    "\n",
    "Fantastic.\n",
    "\n",
    "As you implemented that equals matcher, you had a monologue going on in your head.\n",
    "\n",
    "You asked yourself questions about how to implement it and you found answers—or you _created_ answers.\n",
    "\n",
    "Suppose that you had a transcript of that internal monologue to look over once you complete this matcher.\n",
    "\n",
    "Are there any parts of that monologue that you think would be important for other people on your development team to have access to?\n",
    "\n",
    "For example, maybe you set up the convention of using the `FailedAssertion` for matchers. Is it important that other developers follow that convention? If so, how should they find out about it?\n",
    "\n",
    "It's hard to review your internal monologue ex-post-facto. It's also hard, particularly if you're not practiced at it, to _verbalize_ your monologue while you're developing somethingvery new or unfamiliar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So let's try an exercise that you're going to _hate_. \n",
    "\n",
    "I'd like you to navigate to Voice Memos on your phone, or QuickTime > New Audio Recording on your laptop. \n",
    "\n",
    "Now press \"record\" and read the next three sentences aloud.\n",
    "\n",
    "Implement an `is_empty` matcher while speaking your internal monologue _aloud_. Start by reading the example tests below and stating what you're learning from reading those tests. Think out loud all the way through the exercise until you have implemented the `is_empty` matcher and the example tests pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def test_empty_inputs():\n",
    "        print(\"\")\n",
    "        assert_that(find_twos(\"\", \"\")).is_empty()\n",
    "        assert_that(find_twos(\"2\", \"\")).is_empty()\n",
    "        assert_that(find_twos(\"2\", \"\")).is_empty()\n",
    "\n",
    "    def test_non_matching_sets():\n",
    "        assert_that(find_twos(\"1\", \"1, 3\")).is_empty()\n",
    "\n",
    "    def test_non_matching_twos():\n",
    "        assert_that(find_twos(\"2\", \"1, 3\")).is_empty()\n",
    "        \n",
    "    def test_matches():\n",
    "        assert_that(find_twos(\"12\", \"2, 12\")).equals([12])\n",
    "        assert_that(find_twos(\"1, 2, 20, 22, 44, 99\", \"3, 5, 22, 100, 44, 2\")).equals([2, 22])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_empty_inputs()\n",
    "test_non_matching_sets()\n",
    "test_non_matching_twos()\n",
    "test_matches()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a block of example code to help you get started on the `is_empty` matcher:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Assertion(Assertion): \n",
    "    def is_empty(self):\n",
    "        '''\n",
    "            This method should return True if a collection has no items\n",
    "            And it should raise a FailedAssertion if it doesn't. GO!\n",
    "        '''\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_empty_inputs()\n",
    "test_non_matching_sets()\n",
    "test_non_matching_twos()\n",
    "test_matches()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Done? Great. Now, stop the recording.\n",
    "\n",
    "I'd like you to listen back to that recording, and look for three things:\n",
    "\n",
    "1. What _confused_ you about the code you just read? What might you change about the way that code is either written or documented to make that clearer? Try making those changes.\n",
    "\n",
    "2. What _questions_ did you ask yourself, and what _answers_ did you come up with? Would it be reasonable for other people to come up with _different_ answers? If so, how would you like to let other developers know about your answers?\n",
    "\n",
    "3. Did you make any decisions based on _incomplete_ information? If so, you might have made some assumptions or guesses. What were those? Could any of those guesses turn out to be wrong, or change in the future? If so, would that change the decisions you made? How would you like to note _that_ for other developers, or for your future self? \n",
    "\n",
    "\n",
    "For the next exercise, I will not ask you to record yourself talking. But I would like you to think about those three things:\n",
    "\n",
    "- this is confusing me right now\n",
    "- I am making up an answer to a question right now\n",
    "- I am making a guess or assumption right now\n",
    "\n",
    "and I would like you to think about how you would want to communicate—to _document_ —those things if you _knew_ another developer would become responsible for maintaining this code.\n",
    "\n",
    "With that in mind, please implement the `has_size` assertion below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def test_matches(self):\n",
    "        assert_that(find_twos(\"12\", \"2, 12\")).has_size(1)\n",
    "        assert_that(find_twos(\"12\", \"2, 12\")).equals([12])\n",
    "        assert_that(find_twos(\"1, 2, 20, 22, 44, 99\", \"3, 5, 22, 100, 44, 2\")).has_size(2)\n",
    "        assert_that(find_twos(\"1, 2, 20, 22, 44, 99\", \"3, 5, 22, 100, 44, 2\")).equals([2, 22])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_matches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Assertion(Assertion): \n",
    "    def has_size(self, size):\n",
    "        '''\n",
    "            This method should return True if a collection has the right number of items\n",
    "            And it should raise a FailedAssertion if it doesn't. GO!\n",
    "        '''\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_matches()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What choices did you make? Were any of them _different_ than the choices you made the first time you implemented a matcher in this notebook?\n",
    "\n",
    "Let's do just one more today. One of the annoying things about our implementation right now is that `find_twos` has to return results in a specific _order_ for the assertion to pass. For example, if we check:\n",
    "\n",
    "```\n",
    "assert_that(find_twos(\"1, 2, 20, 22, 44, 99\", \"3, 5, 22, 100, 44, 2\")).equals([2, 22])\n",
    "```\n",
    "\n",
    "And `find_twos` returns `[22, 2]`, it will fail. \n",
    "\n",
    "What if we don't care about order? What if we just want to make sure all the right items are in the collection, regardless of order? Then we could do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def test_matches():\n",
    "        assert_that(find_twos(\"12\", \"2, 12\")).has_size(1)\n",
    "        assert_that(find_twos(\"12\", \"2, 12\")).has_items(12)\n",
    "        assert_that(find_twos(\"1, 2, 20, 22, 44, 99\", \"3, 5, 22, 100, 44, 2\")).has_size(2)\n",
    "        assert_that(find_twos(\"1, 2, 20, 22, 44, 99\", \"3, 5, 22, 100, 44, 2\")).has_items(2, 22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge:\n",
    "\n",
    "Implement the `has_items` assertion.\n",
    "\n",
    "NOTE THAT the implementation above doesn't require the items to be passed in as a collection. Instead, the programmer writing the test can just pass in as many items to this method as they want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Assertion(Assertion): \n",
    "    def has_items(self, *args):\n",
    "        '''\n",
    "            This method should return True if a collection has the right items\n",
    "            And it should raise a FailedAssertion if it doesn't. GO!\n",
    "        '''\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_matches()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are there any _new_ considerations in this last matcher for you to think about in making this code discoverable for other members of the development team? If so, what?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
